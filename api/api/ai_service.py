"""
AI ì„œë¹„ìŠ¤ ì¶”ìƒí™” ë ˆì´ì–´
ë©€í‹° ëª¨ë¸ ì§€ì› (Gemini, GPT, Claude)
Phase 6: ì˜ë„ ë¶„ë¥˜ (Intent Classification)
Phase 7: JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
"""
from django.conf import settings
from google import genai
import json
import re
from . import ai_config


def validate_ai_response(response):
    """
    AI ì‘ë‹µ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ë³´ì •
    
    Args:
        response: AI ëª¨ë¸ì˜ ì‘ë‹µ dict
    
    Returns:
        dict: ê²€ì¦ ë° ë³´ì •ëœ ì‘ë‹µ
    """
    # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
    defaults = {
        'answer': '',
        'claims': [],
        'evidence': [],
        'missing_info': [],
        'confidence': 0.5,
        'actions_suggested': []
    }
    
    # ëˆ„ë½ëœ í•„ë“œ ë³´ì •
    for field, default_value in defaults.items():
        if field not in response:
            response[field] = default_value
    
    # íƒ€ì… ê²€ì¦ ë° ë³´ì •
    if not isinstance(response['answer'], str):
        response['answer'] = str(response['answer'])
    
    if not isinstance(response['claims'], list):
        response['claims'] = []
    
    if not isinstance(response['evidence'], list):
        response['evidence'] = []
    
    if not isinstance(response['missing_info'], list):
        response['missing_info'] = []
    
    if not isinstance(response['confidence'], (int, float)):
        response['confidence'] = 0.5
    else:
        # confidence ë²”ìœ„ ì œí•œ (0~1)
        response['confidence'] = max(0.0, min(1.0, float(response['confidence'])))
    
    if not isinstance(response['actions_suggested'], list):
        response['actions_suggested'] = []
    
    return response


def classify_intent(user_message):
    """
    Jë‹˜ì˜ ì˜ë„(Intent) ê°ì§€
    
    ì„¤ê³„ ì² í•™ (Jë‹˜):
    1. "db" ëª©ì ì–´ = CRUD í™œì„±í™”
    2. "db" ì—†ìŒ = ORGANIZE (ì•ˆì „)
    
    í•µì‹¬:
    - "db ê²€ìƒ‰í•´" â†’ READ (DB ì¡°íšŒ)
    - "db ë¶„ì„í•´" â†’ ORGANIZE (DB ì½ê¸°ë§Œ)
    - "db ìˆ˜ì •í•´" â†’ UPDATE (DB ìˆ˜ì •)
    - "db ì‚­ì œí•´" â†’ DELETE (DB ì‚­ì œ)
    - "ê²€ìƒ‰í•´" â†’ ORGANIZE (ìì—°ì–´, DB ì˜í–¥ ì—†ìŒ)
    
    Returns:
        dict: {
            'intent': 'SAVE' | 'READ' | 'UPDATE' | 'DELETE' | 'ORGANIZE',
            'confidence': 0.95,
            'params': {...}
        }
    
    Jë‹˜ ì„¤ê³„ ì² í•™:
    - ëª…ë ¹ì–´ëŠ” ë‹¨ìˆœí•˜ê²Œ (ë³µí•© ëª…ë ¹ì–´ ì—†ìŒ)
    - ëª¨ë“  ì €ì¥ì€ ëª¨ë‹¬ì°½ (ìë™ ì €ì¥ ì—†ìŒ)
    - ìì—°ì–´ëŠ” AIì—ê²Œ ë§¡ê¹€ (ìµœëŒ€í•œ í™œìš©)
    - DB í†µì œë§Œ ì—„ê²© (ê±°ì§“/í™˜ê°/ë©”ëª¨ë¦¬)
    """
    message = user_message.strip()
    message_lower = message.lower()
    
    # DB ëª©ì ì–´ ì²´í¬ (CRUD í™œì„±í™”)
    has_db = any(db in message_lower for db in ['db', 'database', 'ë°ì´í„°ë² ì´ìŠ¤', 'ë””ë¹„'])
    
    # SAVE (ì—„ê²©: "db" í•„ìˆ˜!)
    # âš ï¸ Jë‹˜ ì² í•™: "db" ëª©ì ì–´ ì—†ìœ¼ë©´ ëª¨ë‘ ORGANIZE
    #   - "dbì— ì €ì¥í•´" â†’ SAVE (CRUD)
    #   - "ì €ì¥í•´" â†’ ORGANIZE (ìì—°ì–´, AIê°€ ì¤€ë¹„ë§Œ í•¨)
    if has_db and any(cmd in message_lower for cmd in ['ì €ì¥í•´', 'ì €ì¥í•´ì¤˜', 'ê¸°ë¡í•´', 'ë³´ê´€í•´']):
        # ì œì™¸: "ì €ì¥í•´ì„œ", "ì €ì¥í•˜ê³ " ë“±
        if not any(exc in message_lower for exc in ['ì €ì¥í•´ì„œ', 'ì €ì¥í•´ë„', 'ì €ì¥í•˜ê³ ', 'ì €ì¥í•˜ë©´']):
            params = {
                'collection': 'final' if any(k in message_lower for k in ['ìµœì¢…', 'final', 'ì™„ë£Œ']) else 'draft',
                'target': 'last_response'
            }
            return {
                'intent': 'SAVE',
                'confidence': 0.95,
                'params': params
            }
    
    # ì¹´í…Œê³ ë¦¬ ëª©ë¡ (í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤ ìš´ë™ ìˆœì„œ)
    categories = ['í•˜ì´ë…¸ì´ë¡ ', 'í•˜ì´ë…¸ì›Œë°', 'í•˜ì´ë…¸ê³¨ë°˜', 'í•˜ì´ë…¸ì›Œí‚¹', 'í•˜ì´ë…¸ìŠ¤ì¼€ì´íŒ…', 'í•˜ì´ë…¸í’‹ì‚½', 'í•˜ì´ë…¸ì² ë´‰', 'í•˜ì´ë…¸ê¸°íƒ€']
    has_category = any(cat in message_lower for cat in categories)
    
    # DELETE (ì—„ê²©: "db" ë˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
    # "db ì‚­ì œí•´" ë˜ëŠ” "í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤ ì‚­ì œí•´" ëª¨ë‘ í—ˆìš©
    if (has_db or has_category) and any(cmd in message_lower for cmd in ['ì‚­ì œí•´', 'ì‚­ì œí•´ì¤˜', 'ì§€ì›Œ', 'ì§€ì›Œì¤˜', 'ì œê±°í•´']):
        if not any(exc in message_lower for exc in ['ì‚­ì œí•´ì„œ', 'ì‚­ì œí•˜ê³ ', 'ì‚­ì œí•˜ë©´']):
            return {
                'intent': 'DELETE',
                'confidence': 0.95,
                'params': {'requires_approval': True}
            }
    
    # UPDATE (ì—„ê²©: "db" í•„ìˆ˜ + ì œì™¸ ì¡°ê±´)
    # âš ï¸ êµ¬ë¶„:
    #   - "db ìˆ˜ì •í•´" â†’ UPDATE (CRUD, ì‹¤ì œ DB ìˆ˜ì •)
    #   - "ìˆ˜ì •í•´ì„œ ë³´ì—¬ì¤˜", "í†µí•©í•´" â†’ ORGANIZE (ìì—°ì–´, DB ì•ˆ ê±´ë“œë¦¼)
    if has_db and any(cmd in message_lower for cmd in ['ìˆ˜ì •í•´', 'ìˆ˜ì •í•´ì¤˜', 'ê³ ì³', 'ê³ ì³ì¤˜', 'ë°”ê¿”', 'ë°”ê¿”ì¤˜', 'ë³€ê²½í•´']):
        # ì œì™¸: ìì—°ì–´ ëª…ë ¹ (AIê°€ ìˆ˜ì •ì•ˆë§Œ ë³´ì—¬ì£¼ê¸°)
        if not any(exc in message_lower for exc in ['ìˆ˜ì •í•´ì„œ', 'ìˆ˜ì •í•´ë„', 'ìˆ˜ì •í•˜ê³ ', 'ìˆ˜ì •í•˜ë©´', 'ë³´ì—¬ì¤˜', 'ë³´ì—¬ì£¼', 'í†µí•©']):
            return {
                'intent': 'UPDATE',
                'confidence': 0.95,
                'params': {'requires_approval': True}
            }
    
    # READ (ì—„ê²©: "db" ë˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
    db_targets = categories + ['draft', 'ì´ˆì•ˆ', 'final', 'ìµœì¢…', 'raw', 'ì›ë³¸', 'í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤']
    
    has_category = any(cat in message_lower for cat in db_targets)
    
    if (has_db or has_category) and any(cmd in message_lower for cmd in ['ê²€ìƒ‰í•´', 'ê²€ìƒ‰í•´ì¤˜', 'ì°¾ì•„ì¤˜', 'ê°€ì ¸ì™€', 'ê°€ì ¸ì™€ì¤˜', 'ì¡°íšŒí•´', 'ë³´ì—¬ì¤˜', 'ë³´ì—¬ì£¼']):
        params = {'collections': []}
        
        # ì»¬ë ‰ì…˜ í•„í„°ë§ (subcollection ì´ë¦„ë§Œ)
        if 'draft' in message_lower or 'ì´ˆì•ˆ' in message_lower:
            params['collections'].append('draft')
        if 'final' in message_lower or 'ìµœì¢…' in message_lower:
            params['collections'].append('final')
        if 'raw' in message_lower or 'ì›ë³¸' in message_lower:
            params['collections'].append('raw')
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤ ìš´ë™ ìˆœì„œ)
        for category in categories:
            if category in message:
                params['category'] = category
                break
        
        return {
            'intent': 'READ',
            'confidence': 0.95,
            'params': params
        }
    
    # ORGANIZE (ìì—°ì–´ ì²˜ë¦¬, DB ì˜í–¥ ì—†ìŒ)
    # "ìˆ˜ì •í•´ì„œ ë³´ì—¬ë‹¬ë¼" = AIê°€ ìˆ˜ì •ì•ˆ ìƒì„± â†’ ë³´ì—¬ì£¼ê¸°ë§Œ
    return {
        'intent': 'ORGANIZE',
        'confidence': 0.95,
        'params': {}
    }


def call_ai_model(model_name, user_message, system_prompt, db_context, temperature=None, mode='hybrid', conversation_history=None):
    """
    AI ëª¨ë¸ í˜¸ì¶œ (ë©€í‹° ëª¨ë¸ ì§€ì›)
    
    Args:
        model_name: 'gemini-flash' | 'gemini-pro' | 'gpt' | 'claude' | 'all'
        user_message: Jë‹˜ì˜ ë©”ì‹œì§€ (v2ì—ì„œëŠ” ì´ë¯¸ ë§¥ë½ì´ í¬í•¨ëœ full_message)
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        db_context: Firestore DB ë°ì´í„° (v2ì—ì„œëŠ” ë¹ˆ ë¬¸ìì—´)
        temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (Noneì´ë©´ modeì— ë”°ë¼ ìë™ ì„¤ì •)
        mode: 'organize' | 'hybrid' | 'analysis' | 'v2'
        conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (v2ì—ì„œëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    
    Returns:
        dict: JSON ì‘ë‹µ (AI_RESPONSE_SCHEMA í˜•ì‹)
    """
    # Temperature ìë™ ì„¤ì • (ai_configì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    if temperature is None:
        temperature = ai_config.TEMPERATURE_SETTINGS.get(mode, 0.5)
    
    # ëª¨ë¸ ì •ë³´ ì£¼ì… (ai_configì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    model_name_korean = ai_config.MODEL_ALIASES.get(model_name, model_name)
    enhanced_prompt = f"ğŸ¯ ë‹¹ì‹ ì˜ ì´ë¦„: {model_name_korean}\n\n{system_prompt}"
    
    # Gemini Native History: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    messages = []
    
    # ëŒ€í™” ì´ë ¥ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì ì¬ (Native History)
    if conversation_history and len(conversation_history) > 0:
        for msg in conversation_history:
            # Gemini API: 'assistant' â†’ 'model'
            role = 'model' if msg['role'] in ['assistant', 'model'] else 'user'
            messages.append({'role': role, 'parts': [{'text': msg['content']}]})
    
    # í˜„ì¬ ìœ ì € ë©”ì‹œì§€ ì¶”ê°€
    messages.append({'role': 'user', 'parts': [{'text': user_message}]})
    
    # DB Contextê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    final_system_prompt = enhanced_prompt
    if db_context:
        final_system_prompt += f"\n\n[ì°¸ê³ í•  DB ì§€ì‹]\n{db_context}"
    
    # Gemini ê³„ì—´ (Flash/Pro) - Native History ì „ë‹¬
    if model_name in ['gemini-flash', 'gemini-pro']:
        return _call_gemini(messages, final_system_prompt, model_key=model_name, temperature=temperature)
    
    # ê¸°ë³¸ê°’ fallback
    elif model_name == 'gemini' or not model_name:
        return _call_gemini(messages, final_system_prompt, model_key=settings.DEFAULT_AI_MODEL, temperature=temperature)
    
    elif model_name == 'gpt':
        # GPT Native History ì ìš©
        return _call_gpt(messages, final_system_prompt, temperature=temperature)
    
    elif model_name == 'claude':
        # Claude Native History ì ìš©
        return _call_claude(messages, final_system_prompt, temperature=temperature)
    
    elif model_name == 'all':
        # ë©€í‹° ëª¨ë¸ì€ ë¬¸ìì—´ë¡œ ë³€í™˜ í•„ìš” (í–¥í›„ ê°œì„ )
        full_message = messages[-1]['parts'][0]['text'] if mode == 'v2' else user_message
        return _call_all_models(full_message, system_prompt, temperature=temperature)
    
    else:
        raise ValueError(f"Unknown model: {model_name}")


def _call_gemini(messages, system_prompt, model_key='gemini-pro', temperature=0.5):
    """Gemini API í˜¸ì¶œ (Native History ì§€ì›)
    
    Args:
        messages: [{'role': 'user'|'model', 'parts': [{'text': '...'}]}] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        model_key: 'gemini-flash' | 'gemini-pro'
        temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (0.0~1.0)
    """
    if model_key not in settings.AI_MODELS:
        model_key = 'gemini-pro'  # fallback
    
    if not settings.AI_MODELS[model_key]['enabled']:
        raise Exception(f"{model_key} not initialized")
    
    client = settings.AI_MODELS[model_key]['client']
    model = settings.AI_MODELS[model_key]['model']
    
    try:
        # Google GenAI SDK í˜¸ì¶œ
        from google.genai import types
        
        print("="*80)
        print(f"ğŸ” [DEBUG] _call_gemini ì‹¤í–‰ ì‹œì‘")
        print(f"   model_key: {model_key}")
        print(f"   model: {model}")
        print(f"   temperature: {temperature}")
        print(f"   messages: {len(messages)} turns")
        print("="*80)
        
        response = client.models.generate_content(
            model=model,
            contents=messages,  # Native History: ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
            config=types.GenerateContentConfig(
                systemInstruction=system_prompt,
                temperature=temperature,
                maxOutputTokens=32768,
                responseMimeType='application/json',
                responseSchema=settings.AI_RESPONSE_SCHEMA,
            )
        )
        
        print(f"âœ… [DEBUG] Gemini ì‘ë‹µ ì„±ê³µ")
        print("="*80)
        
        # JSON íŒŒì‹±
        result = json.loads(response.text)
        result['_model'] = model_key
        result['_model_version'] = model
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': response.text,
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': model_key,
            '_error': str(e)
        }


def _call_gpt(messages, system_prompt, temperature=0.7):
    """GPT API í˜¸ì¶œ (Native History ì§€ì›)"""
    if not settings.AI_MODELS['gpt']['enabled']:
        raise Exception("GPT not initialized")
    
    client = settings.GPT_CLIENT
    model = settings.AI_MODELS['gpt']['model']
    
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ ì‹œì‘ì— ì¶”ê°€
        api_messages = [{"role": "system", "content": f"{system_prompt}\n\në°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n{json.dumps(settings.AI_RESPONSE_SCHEMA, ensure_ascii=False, indent=2)}"}]
        
        # ëŒ€í™” ì´ë ¥ì„ ë³€í™˜í•˜ì—¬ ì¶”ê°€ (Gemini í˜•ì‹ â†’ OpenAI í˜•ì‹)
        for msg in messages:
            # Geminiì˜ 'model' ì—­í• ì„ 'assistant'ë¡œ ë³€ê²½
            role = 'assistant' if msg['role'] == 'model' else msg['role']
            content = msg['parts'][0]['text']
            api_messages.append({"role": role, "content": content})
        
        response = client.chat.completions.create(
            model=model,
            messages=api_messages,  # Native History: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
            temperature=temperature,
            response_format={"type": "json_object"}
        )
        
        # JSON íŒŒì‹±
        content = response.choices[0].message.content
        result = json.loads(content)
        result['_model'] = 'gpt'
        result['_model_version'] = model  # ì‹¤ì œ ëª¨ë¸ëª… ê¸°ë¡
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': content if 'content' in locals() else 'GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨',
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': 'gpt',
            '_error': str(e)
        }
    except Exception as e:
        return {
            'answer': f'GPT í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}',
            'claims': [],
            'evidence': [],
            'missing_info': ['GPT API í˜¸ì¶œ ì‹¤íŒ¨'],
            'confidence': 0.0,
            'actions_suggested': [],
            '_model': 'gpt',
            '_error': str(e)
        }


def _call_claude(messages, system_prompt, temperature=0.7):
    """Claude API í˜¸ì¶œ (Native History ì§€ì›)"""
    if not settings.AI_MODELS['claude']['enabled']:
        raise Exception("Claude not initialized")
    
    client = settings.AI_MODELS['claude']['client']
    model = settings.AI_MODELS['claude']['model']
    
    try:
        # ClaudeëŠ” JSON mode ì§ì ‘ ì§€ì› ì•ˆ í•¨, system promptì— JSON ìš”ì²­ ì¶”ê°€
        enhanced_prompt = f"{system_prompt}\n\në°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n{json.dumps(settings.AI_RESPONSE_SCHEMA, ensure_ascii=False, indent=2)}"
        
        # ëŒ€í™” ì´ë ¥ì„ ë³€í™˜í•˜ì—¬ ì¶”ê°€ (Gemini í˜•ì‹ â†’ Anthropic í˜•ì‹)
        api_messages = []
        for msg in messages:
            # Geminiì˜ 'model' ì—­í• ì„ 'assistant'ë¡œ ë³€ê²½
            role = 'assistant' if msg['role'] == 'model' else msg['role']
            content = msg['parts'][0]['text']
            api_messages.append({"role": role, "content": content})
        
        response = client.messages.create(
            model=model,
            max_tokens=4096,
            temperature=temperature,
            system=enhanced_prompt,
            messages=api_messages  # Native History: ì „ì²´ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
        )
        
        # JSON íŒŒì‹±
        content = response.content[0].text
        result = json.loads(content)
        result['_model'] = 'claude'
        result['_model_version'] = model
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': content if 'content' in locals() else 'Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨',
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': 'claude',
            '_error': str(e)
        }
    except Exception as e:
        return {
            'answer': f'Claude í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}',
            'claims': [],
            'evidence': [],
            'confidence': 0.0,
            '_model': 'claude',
            '_error': str(e)
        }


def _call_all_models(full_message, system_prompt):
    """
    3ë‘/2ë‘ ì²´ê³„: ëª¨ë“  í™œì„±í™”ëœ ëª¨ë¸ í˜¸ì¶œ í›„ ë¹„êµ
    """
    results = {}
    
    for model_name, config in settings.AI_MODELS.items():
        if config['enabled']:
            try:
                if model_name == 'gemini':
                    results[model_name] = _call_gemini(full_message, system_prompt)
                elif model_name == 'gpt':
                    results[model_name] = _call_gpt(full_message, system_prompt)
                elif model_name == 'claude':
                    results[model_name] = _call_claude(full_message, system_prompt)
            except Exception as e:
                results[model_name] = {'error': str(e)}
    
    # í–¥í›„: íˆ¬í‘œ/í•©ì˜ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€
    # í˜„ì¬ëŠ” ëª¨ë“  ê²°ê³¼ ë°˜í™˜
    return {
        'answer': 'ë©€í‹° ëª¨ë¸ ì‘ë‹µ (ì•„ë˜ ì°¸ì¡°)',
        'claims': [],
        'evidence': [],
        'missing_info': [],
        'confidence': 0.0,
        'actions_suggested': [],
        '_model': 'all',
        '_responses': results
    }
