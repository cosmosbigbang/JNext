"""
AI ì„œë¹„ìŠ¤ ì¶”ìƒí™” ë ˆì´ì–´
ë©€í‹° ëª¨ë¸ ì§€ì› (Gemini, GPT, Claude)
Phase 6: ì˜ë„ ë¶„ë¥˜ (Intent Classification)
Phase 7: JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
"""
from django.conf import settings
import json


def validate_ai_response(response):
    """
    AI ì‘ë‹µ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ë³´ì •
    
    Args:
        response: AI ëª¨ë¸ì˜ ì‘ë‹µ dict
    
    Returns:
        dict: ê²€ì¦ ë° ë³´ì •ëœ ì‘ë‹µ
    """
    # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
    defaults = {
        'answer': '',
        'claims': [],
        'evidence': [],
        'missing_info': [],
        'confidence': 0.5,
        'actions_suggested': []
    }
    
    # ëˆ„ë½ëœ í•„ë“œ ë³´ì •
    for field, default_value in defaults.items():
        if field not in response:
            response[field] = default_value
    
    # íƒ€ì… ê²€ì¦ ë° ë³´ì •
    if not isinstance(response['answer'], str):
        response['answer'] = str(response['answer'])
    
    if not isinstance(response['claims'], list):
        response['claims'] = []
    
    if not isinstance(response['evidence'], list):
        response['evidence'] = []
    
    if not isinstance(response['missing_info'], list):
        response['missing_info'] = []
    
    if not isinstance(response['confidence'], (int, float)):
        response['confidence'] = 0.5
    else:
        # confidence ë²”ìœ„ ì œí•œ (0~1)
        response['confidence'] = max(0.0, min(1.0, float(response['confidence'])))
    
    if not isinstance(response['actions_suggested'], list):
        response['actions_suggested'] = []
    
    return response


def classify_intent(user_message):
    """
    Jë‹˜ì˜ ì˜ë„(Intent) ê°ì§€
    
    ì„¤ê³„ ì² í•™ (Jë‹˜):
    1. "db" ëª©ì ì–´ = CRUD í™œì„±í™”
    2. "db" ì—†ìŒ = ORGANIZE (ì•ˆì „)
    
    í•µì‹¬:
    - "db ê²€ìƒ‰í•´" â†’ READ (DB ì¡°íšŒ)
    - "db ë¶„ì„í•´" â†’ ORGANIZE (DB ì½ê¸°ë§Œ)
    - "db ìˆ˜ì •í•´" â†’ UPDATE (DB ìˆ˜ì •)
    - "db ì‚­ì œí•´" â†’ DELETE (DB ì‚­ì œ)
    - "ê²€ìƒ‰í•´" â†’ ORGANIZE (ìì—°ì–´, DB ì˜í–¥ ì—†ìŒ)
    
    Returns:
        dict: {
            'intent': 'SAVE' | 'READ' | 'UPDATE' | 'DELETE' | 'ORGANIZE',
            'confidence': 0.95,
            'params': {...}
        }
    
    Jë‹˜ ì„¤ê³„ ì² í•™:
    - ëª…ë ¹ì–´ëŠ” ë‹¨ìˆœí•˜ê²Œ (ë³µí•© ëª…ë ¹ì–´ ì—†ìŒ)
    - ëª¨ë“  ì €ì¥ì€ ëª¨ë‹¬ì°½ (ìë™ ì €ì¥ ì—†ìŒ)
    - ìì—°ì–´ëŠ” AIì—ê²Œ ë§¡ê¹€ (ìµœëŒ€í•œ í™œìš©)
    - DB í†µì œë§Œ ì—„ê²© (ê±°ì§“/í™˜ê°/ë©”ëª¨ë¦¬)
    """
    message = user_message.strip()
    message_lower = message.lower()
    
    # DB ëª©ì ì–´ ì²´í¬ (CRUD í™œì„±í™”)
    has_db = any(db in message_lower for db in ['db', 'database', 'ë°ì´í„°ë² ì´ìŠ¤', 'ë””ë¹„'])
    
    # SAVE (ì—„ê²©: "db" í•„ìˆ˜!)
    # âš ï¸ Jë‹˜ ì² í•™: "db" ëª©ì ì–´ ì—†ìœ¼ë©´ ëª¨ë‘ ORGANIZE
    #   - "dbì— ì €ì¥í•´" â†’ SAVE (CRUD)
    #   - "ì €ì¥í•´" â†’ ORGANIZE (ìì—°ì–´, AIê°€ ì¤€ë¹„ë§Œ í•¨)
    if has_db and any(cmd in message_lower for cmd in ['ì €ì¥í•´', 'ì €ì¥í•´ì¤˜', 'ê¸°ë¡í•´', 'ë³´ê´€í•´']):
        # ì œì™¸: "ì €ì¥í•´ì„œ", "ì €ì¥í•˜ê³ " ë“±
        if not any(exc in message_lower for exc in ['ì €ì¥í•´ì„œ', 'ì €ì¥í•´ë„', 'ì €ì¥í•˜ê³ ', 'ì €ì¥í•˜ë©´']):
            params = {
                'collection': 'hino_final' if any(k in message_lower for k in ['ìµœì¢…', 'final', 'ì™„ë£Œ']) else 'hino_draft',
                'target': 'last_response'
            }
            return {
                'intent': 'SAVE',
                'confidence': 0.95,
                'params': params
            }
    
    # DELETE (ì—„ê²©: "db" ë˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
    # "db ì‚­ì œí•´" ë˜ëŠ” "í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤ ì‚­ì œí•´" ëª¨ë‘ í—ˆìš©
    if (has_db or has_category) and any(cmd in message_lower for cmd in ['ì‚­ì œí•´', 'ì‚­ì œí•´ì¤˜', 'ì§€ì›Œ', 'ì§€ì›Œì¤˜', 'ì œê±°í•´']):
        if not any(exc in message_lower for exc in ['ì‚­ì œí•´ì„œ', 'ì‚­ì œí•˜ê³ ', 'ì‚­ì œí•˜ë©´']):
            return {
                'intent': 'DELETE',
                'confidence': 0.95,
                'params': {'requires_approval': True}
            }
    
    # UPDATE (ì—„ê²©: "db" í•„ìˆ˜ + ì œì™¸ ì¡°ê±´)
    # âš ï¸ êµ¬ë¶„:
    #   - "db ìˆ˜ì •í•´" â†’ UPDATE (CRUD, ì‹¤ì œ DB ìˆ˜ì •)
    #   - "ìˆ˜ì •í•´ì„œ ë³´ì—¬ì¤˜", "í†µí•©í•´" â†’ ORGANIZE (ìì—°ì–´, DB ì•ˆ ê±´ë“œë¦¼)
    if has_db and any(cmd in message_lower for cmd in ['ìˆ˜ì •í•´', 'ìˆ˜ì •í•´ì¤˜', 'ê³ ì³', 'ê³ ì³ì¤˜', 'ë°”ê¿”', 'ë°”ê¿”ì¤˜', 'ë³€ê²½í•´']):
        # ì œì™¸: ìì—°ì–´ ëª…ë ¹ (AIê°€ ìˆ˜ì •ì•ˆë§Œ ë³´ì—¬ì£¼ê¸°)
        if not any(exc in message_lower for exc in ['ìˆ˜ì •í•´ì„œ', 'ìˆ˜ì •í•´ë„', 'ìˆ˜ì •í•˜ê³ ', 'ìˆ˜ì •í•˜ë©´', 'ë³´ì—¬ì¤˜', 'ë³´ì—¬ì£¼', 'í†µí•©']):
            return {
                'intent': 'UPDATE',
                'confidence': 0.95,
                'params': {'requires_approval': True}
            }
    
    # READ (ì—„ê²©: "db" ë˜ëŠ” ì¹´í…Œê³ ë¦¬ í•„ìˆ˜)
    db_targets = ['í•˜ì´ë…¸ì´ë¡ ', 'í•˜ì´ë…¸ì›Œí‚¹', 'í•˜ì´ë…¸ìŠ¤ì¼€ì´íŒ…', 'í•˜ì´ë…¸ì² ë´‰', 'í•˜ì´ë…¸ê¸°ë³¸', 'í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤',
                  'draft', 'ì´ˆì•ˆ', 'final', 'ìµœì¢…', 'raw', 'ì›ë³¸']
    
    has_category = any(cat in message_lower for cat in db_targets)
    
    if (has_db or has_category) and any(cmd in message_lower for cmd in ['ê²€ìƒ‰í•´', 'ê²€ìƒ‰í•´ì¤˜', 'ì°¾ì•„ì¤˜', 'ê°€ì ¸ì™€', 'ê°€ì ¸ì™€ì¤˜', 'ì¡°íšŒí•´', 'ë³´ì—¬ì¤˜', 'ë³´ì—¬ì£¼']):
        params = {'collections': []}
        
        # ì»¬ë ‰ì…˜ í•„í„°ë§
        if 'draft' in message_lower or 'ì´ˆì•ˆ' in message_lower:
            params['collections'].append('hino_draft')
        if 'final' in message_lower or 'ìµœì¢…' in message_lower:
            params['collections'].append('hino_final')
        if 'raw' in message_lower or 'ì›ë³¸' in message_lower:
            params['collections'].append('hino_raw')
        
        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        categories = ['í•˜ì´ë…¸ì´ë¡ ', 'í•˜ì´ë…¸ì›Œí‚¹', 'í•˜ì´ë…¸ìŠ¤ì¼€ì´íŒ…', 'í•˜ì´ë…¸ì² ë´‰', 'í•˜ì´ë…¸ê¸°ë³¸', 'í•˜ì´ë…¸ë°¸ëŸ°ìŠ¤']
        for category in categories:
            if category in message:
                params['category'] = category
                break
        
        return {
            'intent': 'READ',
            'confidence': 0.95,
            'params': params
        }
    
    # ORGANIZE (ìì—°ì–´ ì²˜ë¦¬, DB ì˜í–¥ ì—†ìŒ)
    # "ìˆ˜ì •í•´ì„œ ë³´ì—¬ë‹¬ë¼" = AIê°€ ìˆ˜ì •ì•ˆ ìƒì„± â†’ ë³´ì—¬ì£¼ê¸°ë§Œ
    return {
        'intent': 'ORGANIZE',
        'confidence': 0.95,
        'params': {}
    }


def call_ai_model(model_name, user_message, system_prompt, db_context, temperature=None, mode='hybrid', conversation_history=None):
    """
    AI ëª¨ë¸ í˜¸ì¶œ (ë©€í‹° ëª¨ë¸ ì§€ì›)
    
    Args:
        model_name: 'gemini-flash' | 'gemini-pro' | 'gpt' | 'claude' | 'all'
        user_message: Jë‹˜ì˜ ë©”ì‹œì§€
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        db_context: Firestore DB ë°ì´í„°
        temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (Noneì´ë©´ modeì— ë”°ë¼ ìë™ ì„¤ì •)
        mode: 'organize' | 'hybrid' | 'analysis'
        conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (list of {'role': 'user'/'assistant', 'content': '...'})
    
    Returns:
        dict: JSON ì‘ë‹µ (AI_RESPONSE_SCHEMA í˜•ì‹)
    """
    # Temperature ìë™ ì„¤ì • (modeì— ë”°ë¼)
    if temperature is None:
        temperature_map = {
            'organize': 0.3,  # ì‚¬ì‹¤ ì¤‘ì‹¬, í™˜ê° ìµœì†Œí™”
            'hybrid': 0.5,    # ê· í˜•
            'analysis': 0.7   # ì°½ì˜ì„± í—ˆìš©
        }
        temperature = temperature_map.get(mode, 0.5)
    
    # ëª¨ë¸ ì •ë³´ ì£¼ì… (Jë‹˜ ëª…ëª…)
    model_info_map = {
        'gemini-pro': 'ì  ',      # Gemini Pro = ì   (ì •í™•í•œ ë†ˆ)
        'gemini-flash': 'ì  ì‹œ',  # Gemini Flash = ì  ì‹œ (ë¹ ë¥¸ ë†ˆ)
        'gpt': 'ì§„'              # GPT-4o = ì§„ (ì°½ì˜ì ì¸ ë†ˆ)
    }
    model_name_korean = model_info_map.get(model_name, model_name)
    enhanced_prompt = f"ğŸ¯ ë‹¹ì‹ ì˜ ì´ë¦„: {model_name_korean}\n\n{system_prompt}"
    
    # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
    history_context = ""
    if conversation_history and len(conversation_history) > 0:
        history_context = "\n\n=== ì´ì „ ëŒ€í™” ë§¥ë½ ===\n"
        for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œë§Œ (5í„´)
            role_kr = "Jë‹˜" if msg['role'] == 'user' else model_name_korean
            history_context += f"{role_kr}: {msg['content']}\n\n"
        history_context += "=== í˜„ì¬ ì§ˆë¬¸ ===\n"
    
    full_message = f"{history_context}{db_context}\n\nJë‹˜ ì§ˆë¬¸: {user_message}"
    
    # Gemini ê³„ì—´ (Flash/Pro)
    if model_name in ['gemini-flash', 'gemini-pro']:
        return _call_gemini(full_message, enhanced_prompt, model_key=model_name, temperature=temperature)
    
    # ê¸°ë³¸ê°’ fallback
    elif model_name == 'gemini' or not model_name:
        return _call_gemini(full_message, enhanced_prompt, model_key=settings.DEFAULT_AI_MODEL, temperature=temperature)
    
    elif model_name == 'gpt':
        return _call_gpt(full_message, enhanced_prompt, temperature=temperature)
    
    elif model_name == 'claude':
        return _call_claude(full_message, enhanced_prompt, temperature=temperature)
    
    elif model_name == 'all':
        # 3ë‘ ì²´ê³„: ëª¨ë“  ëª¨ë¸ í˜¸ì¶œ í›„ ë¹„êµ
        return _call_all_models(full_message, system_prompt, temperature=temperature)
    
    else:
        raise ValueError(f"Unknown model: {model_name}")


def _call_gemini(full_message, system_prompt, model_key='gemini-pro', temperature=0.5):
    """Gemini API í˜¸ì¶œ (JSON ì‘ë‹µ ê°•ì œ)
    
    Args:
        model_key: 'gemini-flash' | 'gemini-pro'
        temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (0.0~1.0)
    """
    if model_key not in settings.AI_MODELS:
        model_key = 'gemini-pro'  # fallback
    
    if not settings.AI_MODELS[model_key]['enabled']:
        raise Exception(f"{model_key} not initialized")
    
    client = settings.AI_MODELS[model_key]['client']
    model = settings.AI_MODELS[model_key]['model']
    
    try:
        response = client.models.generate_content(
            model=model,
            contents=full_message,
            config={
                'system_instruction': system_prompt,
                'temperature': temperature,  # ëª¨ë“œë³„ temperature ì ìš©
                'max_output_tokens': 32768,  # â­ ê¸´ ë¬¸ì„œ ì¶œë ¥ ê°€ëŠ¥ (ê¸°ë³¸ 8192 â†’ 32768)
                'response_mime_type': 'application/json',  # JSON ê°•ì œ
                'response_schema': settings.AI_RESPONSE_SCHEMA,  # ìŠ¤í‚¤ë§ˆ ê°•ì œ
            }
        )
        
        # JSON íŒŒì‹±
        result = json.loads(response.text)
        result['_model'] = model_key
        result['_model_version'] = model
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': response.text,
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': model_key,
            '_error': str(e)
        }


def _call_gpt(full_message, system_prompt, temperature=0.7):
    """GPT-4o API í˜¸ì¶œ (OpenAI)"""
    if not settings.AI_MODELS['gpt']['enabled']:
        raise Exception("GPT not initialized")
    
    client = settings.GPT_CLIENT
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"{system_prompt}\n\në°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n{json.dumps(settings.AI_RESPONSE_SCHEMA, ensure_ascii=False, indent=2)}"},
                {"role": "user", "content": full_message}
            ],
            temperature=temperature,
            response_format={"type": "json_object"}
        )
        
        # JSON íŒŒì‹±
        content = response.choices[0].message.content
        result = json.loads(content)
        result['_model'] = 'gpt'
        result['_model_version'] = 'gpt-4o'
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': content if 'content' in locals() else 'GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨',
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': 'gpt',
            '_error': str(e)
        }
    except Exception as e:
        return {
            'answer': f'GPT í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}',
            'claims': [],
            'evidence': [],
            'missing_info': ['GPT API í˜¸ì¶œ ì‹¤íŒ¨'],
            'confidence': 0.0,
            'actions_suggested': [],
            '_model': 'gpt',
            '_error': str(e)
        }


def _call_claude(full_message, system_prompt, temperature=0.7):
    """Claude API í˜¸ì¶œ"""
    if not settings.AI_MODELS['claude']['enabled']:
        raise Exception("Claude not initialized")
    
    client = settings.AI_MODELS['claude']['client']
    model = settings.AI_MODELS['claude']['model']
    
    try:
        # ClaudeëŠ” JSON mode ì§ì ‘ ì§€ì› ì•ˆ í•¨, system promptì— JSON ìš”ì²­ ì¶”ê°€
        enhanced_prompt = f"{system_prompt}\n\në°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n{json.dumps(settings.AI_RESPONSE_SCHEMA, ensure_ascii=False, indent=2)}"
        
        response = client.messages.create(
            model=model,
            max_tokens=4096,
            temperature=temperature,
            system=enhanced_prompt,
            messages=[
                {"role": "user", "content": full_message}
            ]
        )
        
        # JSON íŒŒì‹±
        content = response.content[0].text
        result = json.loads(content)
        result['_model'] = 'claude'
        result['_model_version'] = model
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        return validate_ai_response(result)
        
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        return {
            'answer': content if 'content' in locals() else 'Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨',
            'claims': [],
            'evidence': [],
            'missing_info': ['JSON ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
            'confidence': 0.5,
            'actions_suggested': [],
            '_model': 'claude',
            '_error': str(e)
        }
    except Exception as e:
        return {
            'answer': f'Claude í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}',
            'claims': [],
            'evidence': [],
            'confidence': 0.0,
            '_model': 'claude',
            '_error': str(e)
        }


def _call_all_models(full_message, system_prompt):
    """
    3ë‘/2ë‘ ì²´ê³„: ëª¨ë“  í™œì„±í™”ëœ ëª¨ë¸ í˜¸ì¶œ í›„ ë¹„êµ
    """
    results = {}
    
    for model_name, config in settings.AI_MODELS.items():
        if config['enabled']:
            try:
                if model_name == 'gemini':
                    results[model_name] = _call_gemini(full_message, system_prompt)
                elif model_name == 'gpt':
                    results[model_name] = _call_gpt(full_message, system_prompt)
                elif model_name == 'claude':
                    results[model_name] = _call_claude(full_message, system_prompt)
            except Exception as e:
                results[model_name] = {'error': str(e)}
    
    # í–¥í›„: íˆ¬í‘œ/í•©ì˜ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€
    # í˜„ì¬ëŠ” ëª¨ë“  ê²°ê³¼ ë°˜í™˜
    return {
        'answer': 'ë©€í‹° ëª¨ë¸ ì‘ë‹µ (ì•„ë˜ ì°¸ì¡°)',
        'claims': [],
        'evidence': [],
        'missing_info': [],
        'confidence': 0.0,
        'actions_suggested': [],
        '_model': 'all',
        '_responses': results
    }
